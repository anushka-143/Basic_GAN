#building GAN model that generates fashion images
'''
1. dataset -> tensorflow fashion dataset(fashion MNIST)
2. Build generator -> will generate images
3. Discriminator -> will discriminate or classify the images between 0 and 1, here 0 will represent real images and 1
represent fake images generated by GAN model
4. Training loop -> will try to balance the training between generator and discriminator
note : Discriminator will get rewarded if it picks the fake images and Generator will get rewarded if its able to fool
the discriminator
'''

'''
Steps:
1. import dependencies and data
2. vizualize data and build pipeline
3. build neural network
4.construct training loop
5. test our generator
'''

############################################### import dependencies #################################################
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import keras
import tensorflow_datasets as tfds

gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)

data = tfds.load('fashion_mnist', split='train')


################################################## vizualize data #################################################

# do some data transformation

##setup connection aka iterator
data_iterator = data.as_numpy_iterator()

#getting data out of pipeline
data_iterator.next()

fig, ax = plt.subplots(ncols=4,figsize=(10,4))
#loop 4 times and get images
for idx in range(4):
    sample = data_iterator.next()
    ax[idx].imshow(np.squeeze(sample['image']))
    ax[idx].title.set_text(sample['label'])
plt.show()

#Scale and return images only
def scale_images(img_data):
    image = img_data['image']
    return image/255
###################################################### build pipeline #################################################

'''steps we perform when we build a data pipeline for tensorflow
1. map 
2. cache
3. shuffle
4. batch
5. prefetch
'''

#maping -> will running the dataset through the scale_images preprocessing step
data = data.map(scale_images)

#caching the dataset for that batch
data = data.cache()

#shuffle it up
data = data.shuffle(60000)

#batch into 128 images per sample
data = data.batch(128)

#prefetch -> reduces the likelihood of bottlenecking
data = data.prefetch(64)

'''we use the "map" operation to transform data, "cache" to store intermediate results for faster access, "shuffle"
to randomize data order for better learning, "batch" to group data elements together for efficient processing, and 
"prefetch" to fetch upcoming data in advance to avoid delays and keep the pipeline running smoothly.'''
data =data.as_numpy_iterator().next().shape

#################################### build neural network #############################################################

# import modelling components
'''Bringing in sequential API for Generator and Discriminator and layers for the neural network'''
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten,Reshape, Dropout,UpSampling2D, LeakyReLU

#creating generator


def build_generator():
    model = Sequential([
        #takes in random values and reshapes it to 7*7*128
        #beginnings of a generated images
        keras.layers.Dense(7*7*128, input_dim=128, activation='relu'),
        keras.layers.Reshape((7,7,128)),

        #upsampling block 1
        keras.layers.UpSampling2D(),
        keras.layers.Conv2D(128, 5, padding='same', activation='relu'),

        #upsampling block 2
        keras.layers.UpSampling2D(),
        keras.layers.Conv2D(128, 5, padding='same', activation='relu'),

        #Convolutional block 1
        keras.layers.Conv2D(128, 4, padding='same', activation='relu'),

        #Convolutional block 2
        keras.layers.Conv2D(128, 4, padding='same', activation='relu'),

        #final Conv layer to get to one channel
        keras.layers.Conv2D(1, 4, padding='same', activation='sigmoid')


    ])
    return model

test_model = build_generator()

generator = build_generator()
img = generator.predict(np.random.randn(4,128,1))
#print(img)

fig, ax = plt.subplots(ncols=4,figsize=(10,4))
#loop 4 times and get images
for idx, img in enumerate(img):
    ax[idx].imshow(np.squeeze(img))
    ax[idx].title.set_text(idx)
plt.show()


######################################  building discriminator ##################################################
def build_discriminator():
    model = Sequential([
        #Convolutional block 1
        keras.layers.Conv2D(32,5,input_shape=(28,28,1),activation='relu'),
        keras.layers.Dropout(0.4),

        #Convolutional block 2
        keras.layers.Conv2D(64,5,activation='relu'),
        keras.layers.Dropout(0.4),

        #Convolutional block 3
        keras.layers.Conv2D(128,5,activation='relu'),
        keras.layers.Dropout(0.4),

        #Convolutional block 4
        keras.layers.Conv2D(256,5,activation='relu'),
        keras.layers.Dropout(0.4),

        #flatten and pass to dense layer
        keras.layers.Flatten(),
        keras.layers.Dropout(0.4),
        keras.layers.Dense(1,activation='sigmoid')

    ])

    return model

discriminator = build_discriminator()
print(discriminator.summary())

print(discriminator.predict(np.expand_dims(img,0)))

############################################ Build a custom Training Loop ###############################################
'''reason why It is considered difficult to train is to find the balance between the speed which discriminator trains and 
 the speed at which generator ables to learn.'''

#setup losses and optimizers for both generator and discriminator
from keras.losses import BinaryCrossentropy
from keras.optimizers import Adam
g_opt = Adam(learning_rate = 0.0001)
d_opt = Adam(learning_rate = 0.00001)
g_loss = BinaryCrossentropy()
d_loss = BinaryCrossentropy()

#Building subclassed model
from keras.models import Model
class FashionGAN(Model):
    def __init__(self, generator, discriminator, *args, **kwargs):
        super().__init__(*args,**kwargs)


        #create attributes for generator and discriminator
        self.generator = generator
        self.discriminator = discriminator


    def train_step(self,g_opt,d_opt,g_loss,d_loss, *args, **kwargs):
        #compile with base class
        super().compile(*args,**kwargs)

        #create attributes for losses and optimizers
        self.g_opt = g_opt
        self.d_opt = d_opt
        self.g_loss = g_loss
        self.d_loss = d_loss


    def test_step(self, batch):
        #get real images
        real_images = batch
        fake_images = self.generator(tf.random.normal((128,128,1)),traing = False)

        #train discriminator
        with tf.GradientTape() as d_tape:
            #pass the real and fake images
            yhat_real = self.discriminator(real_images, training = True)
            yhat_fake = self.discriminator(fake_images, training = True)
            yhat_realfake = tf.concat([yhat_real,yhat_fake],axis = 0)

            #create labels for real and fake images
            y_realfake = tf.concat([tf.zeros_like(yhat_real),tf.ones_like(yhat_fake)],axis = 0)

            #add some noise to the outputs
            noise_real = 0.15*tf.random.uniform(tf.shape(yhat_real))
            noise_fake = -0.15*tf.random.uniform(tf.shape(yhat_fake))
            y_realfake += tf.concat([noise_real,noise_fake],axis = 0)

            #calculate the loss

            total_d_loss = self.d_loss(y_realfake,yhat_realfake)

        #apply backpropogation
        dgrad = d_tape.gradient(total_d_loss,self.discriminator.trainable_variables)
        self.d_opt.apply_gradients(zip(dgrad,self.discriminator.trainable_variables))


        #train the generator
        with tf.GradientTape() as g_tape:
            #generate new images
            gen_images = self.generator(tf.random.normal((128,128,1)),training = True)

            #create the predicted labels
            predicted_labels = self.discriminator(gen_images,training = False)

            #calculate the loss -> here we will try to confuse our discriminator
            total_g_loss = self.g_loss(tf.zeros_like(predicted_labels),predicted_labels)
        #apply backpropogation
        ggrad = g_tape.gradient(total_g_loss,self.generator.trainable_variables)
        self.g_opt.apply_gradients(zip(ggrad,self.generator.trainable_variables))

        return {'d_loss':total_d_loss,'g_loss':total_g_loss}

fashgan = FashionGAN(generator,discriminator)
fashgan.compile(g_opt,d_opt,g_loss,d_loss)

#build callback
import os
from keras.preprocessing.image import array_to_img
from keras.callbacks import Callback

class ModelMonitor(Callback):

    def __init__(self,num_img = 3,latent_dim =128):
        self.num_img = num_img
        self.latent_dim = latent_dim

    def on_epoch_end(self, epoch, logs=None):
        random_latent_vectors = tf.random.uniform((self.num_img, self.latent_dim,1))
        generated_images = self.model.generator(random_latent_vectors)
        generated_images *=255
        generated_images.numpy()
        for i in range(self.num_img):
            img = array_to_img(generated_images[i])
            img.save(os.path.join('Images',f'generated_img_{epoch}_{i}.png'))
hist = fashgan.fit(data, epochs=20, callbacks=[ModelMonitor()])



plt.suptitle('Loss')
plt.plot(hist.history['d_loss'], label='d_loss')
plt.plot(hist.history['g_loss'], label='g_loss')
plt.legend()
plt.show()

############################################## Test our Generator #################################################
generator.load_weights(os.path.join('archive', 'generatormodel.h5'))

imgs = generator.predict(tf.random.normal((16, 128, 1)))

fig, ax = plt.subplots(ncols=4, nrows=4, figsize=(10,10))
for r in range(4):
    for c in range(4):
        ax[r][c].imshow(imgs[(r+1)*(c+1)-1])

# save model
generator.save('generator.h5')
discriminator.save('discriminator.h5')
